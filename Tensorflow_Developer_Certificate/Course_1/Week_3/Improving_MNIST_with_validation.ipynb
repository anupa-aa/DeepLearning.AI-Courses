{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0KPseaZamU8NKYaqbJ60N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupa-aa/DeepLearning.AI-Courses/blob/master/Improving_MNIST_with_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3: Improve MNIST with Convolutions\n",
        "\n",
        "In the videos you looked at how you would improve Fashion MNIST using Convolutions. For this exercise see if you can improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer to the model from the  assignment of the previous week.\n",
        "\n",
        "You should stop training once the accuracy goes above this amount. It should happen in less than 10 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your callback.\n",
        "\n",
        "When 99.5% accuracy has been hit, you should print out the string \"Reached 99.5% accuracy so cancelling training!\"\n"
      ],
      "metadata": {
        "id": "QX6znGAwnbrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing modules"
      ],
      "metadata": {
        "id": "GU-Od4wEwiGZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a22ceS2SnUps"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "783nbQNqwuHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"/mnist.npz\")\n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), (validation_images, validation_labels) = tf.keras.datasets.mnist.load_data(path=data_path)\n"
      ],
      "metadata": {
        "id": "2Ae63N8Pwtz0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing the data\n",
        "\n",
        "One important step when dealing with image data is to preprocess the data. During the preprocess step you can apply transformations to the dataset that will be fed into your convolutional neural network.\n",
        "\n",
        "Here you will apply two transformations to the data:\n",
        "- Reshape the data so that it has an extra dimension. The reason for this\n",
        "is that commonly you will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
        "\n",
        "\n",
        "- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.\n",
        "\n",
        "Remember that these tensors are of type `numpy.ndarray` so you can use functions like [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) or [divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) to complete the `reshape_and_normalize` function below:"
      ],
      "metadata": {
        "id": "ELSNAVDaxSIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # Normalize pixel values\n",
        "    images = images/255\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "xeruoALjxAKk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), (validation_images, _) = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "validation_images = reshape_and_normalize(validation_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORnEpXvYxZi6",
        "outputId": "da48c2ed-6506-49e5-92df-5d5b51399b43"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining your callback\n",
        "\n",
        "Now complete the callback that will ensure that training will stop after an accuracy of 99.5% is reached.\n",
        "\n",
        "Define your callback in such a way that it checks for the metric `accuracy` (`acc` can normally be used as well but the grader expects this metric to be called `accuracy` so to avoid getting grading errors define it using the full word)."
      ],
      "metadata": {
        "id": "FzBV6vRaxeeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jLdz1LCmxedO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember to inherit from the correct class\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get(\"val_accuracy\") is not None and logs.get(\"val_accuracy\") > 0.99:\n",
        "            print(\"Reached 99% accuracy so stopped training\")\n",
        "            self.model.stop_training = True\n",
        "    # Define the method that checks the accuracy at the end of each epoch"
      ],
      "metadata": {
        "id": "grtkuQU6xbVD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Model\n",
        "\n",
        "Finally, complete the `convolutional_model` function below. This function should return your convolutional neural network.\n",
        "\n",
        "**Your model should achieve an accuracy of 99.5% or more before 10 epochs to pass this assignment.**\n",
        "\n",
        "**Hints:**\n",
        "- You can try any architecture for the network but try to keep in mind you don't need a complex one. For instance, only one convolutional layer is needed.\n",
        "- In case you need extra help you can check out an architecture that works pretty well at the end of this notebook.\n",
        "- To avoid timeout issues with the autograder, please limit the number of units in your convolutional and dense layers. An exception will be raised if your model is too large."
      ],
      "metadata": {
        "id": "N0b_w9WgxqKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: convolutional_model\n",
        "def deep_convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
        "        keras.layers.MaxPooling2D(2,2),\n",
        "        keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "        keras.layers.MaxPooling2D(2,2),\n",
        "        keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(64,activation=\"relu\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ])\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "uW-S2Ed7xtJE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### THIS ONE IS BETTER THAN THE ONE ABOVE!\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
        "        keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128,activation=\"relu\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ])\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZqDNemJA3qfC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model 1"
      ],
      "metadata": {
        "id": "VqlJSxue0vjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Get number of weights\n",
        "model_params = model.count_params()\n",
        "\n",
        "# Unit test to limit the size of the model\n",
        "assert model_params < 1000000, (\n",
        "    f'Your model has {model_params:,} params. For successful grading, please keep it '\n",
        "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
        ")\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10,\n",
        "                    validation_data=(validation_images, validation_labels),\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJRSs75BxtIB",
        "outputId": "b7273628-71c7-4e2d-de39-a185387343c6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 0.1493 - accuracy: 0.9561 - val_loss: 0.0616 - val_accuracy: 0.9796\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0523 - accuracy: 0.9838 - val_loss: 0.0480 - val_accuracy: 0.9846\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0344 - accuracy: 0.9890 - val_loss: 0.0409 - val_accuracy: 0.9866\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0486 - val_accuracy: 0.9848\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0495 - val_accuracy: 0.9862\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0447 - val_accuracy: 0.9870\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0454 - val_accuracy: 0.9874\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0516 - val_accuracy: 0.9873\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0578 - val_accuracy: 0.9848\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0600 - val_accuracy: 0.9853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model 2"
      ],
      "metadata": {
        "id": "HJgKz01C6lYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your untrained model\n",
        "model = deep_convolutional_model()\n",
        "\n",
        "# Get number of weights\n",
        "model_params = model.count_params()\n",
        "\n",
        "# Unit test to limit the size of the model\n",
        "assert model_params < 1000000, (\n",
        "    f'Your model has {model_params:,} params. For successful grading, please keep it '\n",
        "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
        ")\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10,\n",
        "                    validation_data=(validation_images, validation_labels),\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5egiax62oVR",
        "outputId": "4be923bb-aff0-401a-858e-4df370ac9d23"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 41s 5ms/step - loss: 0.1724 - accuracy: 0.9471 - val_loss: 0.0512 - val_accuracy: 0.9841\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0556 - accuracy: 0.9830 - val_loss: 0.0434 - val_accuracy: 0.9869\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0314 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9920Reached 99% accuracy so stopped training\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0273 - val_accuracy: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V5ECggwK6uRt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}