{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cats and Dogs using Transfer Learning from InceptionV3","metadata":{}},{"cell_type":"markdown","source":"We will leverage the trained layers from InceptionV3.\n\n1. Get superior convolutional layers from pre trained model\n2. Attatch dense layers to the end of these convolutional layers\n3. Train the dense network\n\nWe will effectively be using the results of training a very deep neural network and tweaking it for our dataset.","metadata":{}},{"cell_type":"markdown","source":"## Setup of pre trained model","metadata":{}},{"cell_type":"markdown","source":"1. Set the input shape to fit our application. We will be setting this to (150,150,3)\n2. Pick and \"freeze\" the convolution layers to use the features it has learnt already\n3. Add dense layers which we will train","metadata":{}},{"cell_type":"code","source":"# Fetch the pre trained weights of InceptionV3\n# Remove the fully connected layer at the end\n# Specify the input shape that the model will accept\n# Freeze the weights of these layers as they have been trained already\n\n# Step 1: Fetching the weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n    \nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-05T20:27:26.931261Z","iopub.execute_input":"2023-08-05T20:27:26.931749Z","iopub.status.idle":"2023-08-05T20:27:28.672847Z","shell.execute_reply.started":"2023-08-05T20:27:26.931707Z","shell.execute_reply":"2023-08-05T20:27:28.671584Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-08-05 20:27:27--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 87910968 (84M) [application/x-hdf]\nSaving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n\n/tmp/inception_v3_w 100%[===================>]  83.84M   172MB/s    in 0.5s    \n\n2023-08-05 20:27:28 (172 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import layers\n\n# Inititialise the base by :\n# Step 2 : Set the input shape and remove the layers we dont need\n\npre_trained_model = InceptionV3(input_shape = (150,150,3),\n                               include_top = False, # We will make our own top layer\n                               weights=None) # Weights none for now load them in the next line\n\npre_trained_model.load_weights(local_weights_file)\n\n# Freeze the weights\nfor layer in pre_trained_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:28.675699Z","iopub.execute_input":"2023-08-05T20:27:28.676114Z","iopub.status.idle":"2023-08-05T20:27:43.216009Z","shell.execute_reply.started":"2023-08-05T20:27:28.676075Z","shell.execute_reply":"2023-08-05T20:27:43.214812Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Look at how impressive this pre trained model is\npre_trained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:43.220662Z","iopub.execute_input":"2023-08-05T20:27:43.221269Z","iopub.status.idle":"2023-08-05T20:27:44.167029Z","shell.execute_reply.started":"2023-08-05T20:27:43.221231Z","shell.execute_reply":"2023-08-05T20:27:44.166203Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model: \"inception_v3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n ing2D)                                                                                           \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n                                                                  'activation_7[0][0]',           \n                                                                  'activation_10[0][0]',          \n                                                                  'activation_11[0][0]']          \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n                                                                                                  \n average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n                                                                  'activation_14[0][0]',          \n                                                                  'activation_17[0][0]',          \n                                                                  'activation_18[0][0]']          \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n                                                                                                  \n batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n                                                                                                  \n conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n                                                                                                  \n activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n                                                                                                  \n average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n                                                                                                  \n activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n                                                                                                  \n mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n                                                                  'activation_21[0][0]',          \n                                                                  'activation_24[0][0]',          \n                                                                  'activation_25[0][0]']          \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n                                                                                                  \n conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n                                                                                                  \n conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n                                                                                                  \n activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n                                                                                                  \n mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n                                                                  'activation_29[0][0]',          \n                                                                  'max_pooling2d_2[0][0]']        \n                                                                                                  \n conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n                                                                                                  \n conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n                                                                                                  \n batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n                                                                                                  \n conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n                                                                                                  \n activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n                                                                                                  \n conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n                                                                                                  \n conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n                                                                                                  \n activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n                                                                                                  \n average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n                                                                                                  \n conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n                                                                                                  \n conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n                                                                                                  \n activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n                                                                                                  \n activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n                                                                                                  \n activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n                                                                                                  \n mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n                                                                  'activation_33[0][0]',          \n                                                                  'activation_38[0][0]',          \n                                                                  'activation_39[0][0]']          \n                                                                                                  \n conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n                                                                                                  \n conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n                                                                                                  \n batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n                                                                                                  \n conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n                                                                                                  \n batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n                                                                                                  \n activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n                                                                                                  \n conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n                                                                                                  \n conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n                                                                                                  \n batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n                                                                                                  \n activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n                                                                                                  \n average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n                                                                                                  \n conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n                                                                                                  \n conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n                                                                                                  \n batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n                                                                                                  \n activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n                                                                                                  \n activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n                                                                                                  \n activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n                                                                                                  \n mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n                                                                  'activation_43[0][0]',          \n                                                                  'activation_48[0][0]',          \n                                                                  'activation_49[0][0]']          \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n                                                                                                  \n batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n                                                                                                  \n conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n                                                                                                  \n batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n                                                                                                  \n activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n                                                                                                  \n batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n                                                                                                  \n activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n                                                                                                  \n average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n                                                                                                  \n conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n                                                                                                  \n conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n                                                                                                  \n batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n                                                                                                  \n activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n                                                                                                  \n activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n                                                                                                  \n activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n                                                                                                  \n mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n                                                                  'activation_53[0][0]',          \n                                                                  'activation_58[0][0]',          \n                                                                  'activation_59[0][0]']          \n                                                                                                  \n conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n                                                                                                  \n conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n                                                                                                  \n batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n                                                                                                  \n conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n                                                                                                  \n batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n                                                                                                  \n activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n                                                                                                  \n conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n                                                                                                  \n conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n                                                                                                  \n batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n                                                                                                  \n activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n                                                                                                  \n average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n                                                                                                  \n conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n                                                                                                  \n conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n                                                                                                  \n batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n                                                                                                  \n activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n                                                                                                  \n activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n                                                                                                  \n activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n                                                                                                  \n mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n                                                                  'activation_63[0][0]',          \n                                                                  'activation_68[0][0]',          \n                                                                  'activation_69[0][0]']          \n                                                                                                  \n conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n                                                                                                  \n batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n                                                                                                  \n conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n                                                                                                  \n batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n                                                                                                  \n conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n                                                                                                  \n conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n                                                                                                  \n batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n                                                                                                  \n activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n                                                                                                  \n conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n                                                                                                  \n conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n                                                                                                  \n batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n                                                                                                  \n activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n                                                                                                  \n mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n                                                                  'activation_75[0][0]',          \n                                                                  'max_pooling2d_3[0][0]']        \n                                                                                                  \n conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n                                                                                                  \n batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n                                                                                                  \n conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n                                                                                                  \n conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n                                                                                                  \n batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n                                                                                                  \n activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n                                                                                                  \n conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n                                                                                                  \n conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n                                                                                                  \n conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n                                                                                                  \n conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n                                                                                                  \n average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n                                                                                                  \n batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n                                                                                                  \n batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n                                                                                                  \n activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n                                                                                                  \n activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n                                                                                                  \n activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n                                                                                                  \n batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n                                                                                                  \n mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n                                                                  'activation_79[0][0]']          \n                                                                                                  \n concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n                                                                  'activation_83[0][0]']          \n                                                                                                  \n activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n                                                                                                  \n mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n                                                                  'mixed9_0[0][0]',               \n                                                                  'concatenate[0][0]',            \n                                                                  'activation_84[0][0]']          \n                                                                                                  \n conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n                                                                                                  \n batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n                                                                                                  \n conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n                                                                                                  \n conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n                                                                                                  \n batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n                                                                                                  \n activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n                                                                                                  \n conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n                                                                                                  \n conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n                                                                                                  \n conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n                                                                                                  \n conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n                                                                                                  \n average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n                                                                                                  \n batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n                                                                                                  \n batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n                                                                                                  \n activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n                                                                                                  \n activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n                                                                                                  \n activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n                                                                                                  \n batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n                                                                                                  \n mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n                                                                  'activation_88[0][0]']          \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n                                                                  'activation_92[0][0]']          \n                                                                                                  \n activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n                                                                                                  \n mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n                                                                  'mixed9_1[0][0]',               \n                                                                  'concatenate_1[0][0]',          \n                                                                  'activation_93[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 21,802,784\nTrainable params: 0\nNon-trainable params: 21,802,784\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Designing the model\n\nWe will need to check the output shape. Using a lower layer will mean a smaller output shape, lets aim for an reasonably sized output shape to feed into our Dense neural network","metadata":{}},{"cell_type":"code","source":"# Lets use \"mixed7\" as the last layer of the base model\nlast_layer = pre_trained_model.get_layer(\"mixed7\")\nprint(f\"Last Layer output shape : \", last_layer.output_shape)\nlast_output = last_layer.output","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:44.169851Z","iopub.execute_input":"2023-08-05T20:27:44.170197Z","iopub.status.idle":"2023-08-05T20:27:44.182467Z","shell.execute_reply.started":"2023-08-05T20:27:44.170162Z","shell.execute_reply":"2023-08-05T20:27:44.181706Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Last Layer output shape :  (None, 7, 7, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import Model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten() (last_output)\n\n# Add a fully connected layer with 1024 hidden units and relu activation\nx = layers.Dense(1024, activation=\"relu\")(x)\n\n# Add dropout with rate 0.2\nx = layers.Dropout(0.2)(x)\n\n# Add our final output layer\nx = layers.Dense(1, activation=\"sigmoid\")(x)\n\n### Finally, append the dense network to the base model\nmodel = Model(pre_trained_model.input, x)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:44.183447Z","iopub.execute_input":"2023-08-05T20:27:44.183811Z","iopub.status.idle":"2023-08-05T20:27:44.795679Z","shell.execute_reply.started":"2023-08-05T20:27:44.183776Z","shell.execute_reply":"2023-08-05T20:27:44.794898Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n ing2D)                                                                                           \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n                                                                  'activation_7[0][0]',           \n                                                                  'activation_10[0][0]',          \n                                                                  'activation_11[0][0]']          \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n                                                                                                  \n average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n                                                                  'activation_14[0][0]',          \n                                                                  'activation_17[0][0]',          \n                                                                  'activation_18[0][0]']          \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n                                                                                                  \n batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n                                                                                                  \n conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n                                                                                                  \n activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n                                                                                                  \n average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n                                                                                                  \n activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n                                                                                                  \n mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n                                                                  'activation_21[0][0]',          \n                                                                  'activation_24[0][0]',          \n                                                                  'activation_25[0][0]']          \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n                                                                                                  \n conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n                                                                                                  \n conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n                                                                                                  \n activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n                                                                                                  \n mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n                                                                  'activation_29[0][0]',          \n                                                                  'max_pooling2d_2[0][0]']        \n                                                                                                  \n conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n                                                                                                  \n conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n                                                                                                  \n batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n                                                                                                  \n conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n                                                                                                  \n activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n                                                                                                  \n conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n                                                                                                  \n conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n                                                                                                  \n activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n                                                                                                  \n average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n                                                                                                  \n conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n                                                                                                  \n conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n                                                                                                  \n activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n                                                                                                  \n activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n                                                                                                  \n activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n                                                                                                  \n mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n                                                                  'activation_33[0][0]',          \n                                                                  'activation_38[0][0]',          \n                                                                  'activation_39[0][0]']          \n                                                                                                  \n conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n                                                                                                  \n conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n                                                                                                  \n batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n                                                                                                  \n conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n                                                                                                  \n batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n                                                                                                  \n activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n                                                                                                  \n conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n                                                                                                  \n conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n                                                                                                  \n batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n                                                                                                  \n activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n                                                                                                  \n average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n                                                                                                  \n conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n                                                                                                  \n conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n                                                                                                  \n batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n                                                                                                  \n activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n                                                                                                  \n activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n                                                                                                  \n activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n                                                                                                  \n mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n                                                                  'activation_43[0][0]',          \n                                                                  'activation_48[0][0]',          \n                                                                  'activation_49[0][0]']          \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n                                                                                                  \n batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n                                                                                                  \n conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n                                                                                                  \n batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n                                                                                                  \n activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n                                                                                                  \n batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n                                                                                                  \n activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n                                                                                                  \n average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n                                                                                                  \n conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n                                                                                                  \n conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n                                                                                                  \n batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n                                                                                                  \n activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n                                                                                                  \n activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n                                                                                                  \n activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n                                                                                                  \n mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n                                                                  'activation_53[0][0]',          \n                                                                  'activation_58[0][0]',          \n                                                                  'activation_59[0][0]']          \n                                                                                                  \n conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n                                                                                                  \n conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n                                                                                                  \n batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n                                                                                                  \n conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n                                                                                                  \n batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n                                                                                                  \n activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n                                                                                                  \n conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n                                                                                                  \n conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n                                                                                                  \n batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n                                                                                                  \n activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n                                                                                                  \n average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n                                                                                                  \n conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n                                                                                                  \n conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n                                                                                                  \n batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n                                                                                                  \n activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n                                                                                                  \n activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n                                                                                                  \n activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n                                                                                                  \n mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n                                                                  'activation_63[0][0]',          \n                                                                  'activation_68[0][0]',          \n                                                                  'activation_69[0][0]']          \n                                                                                                  \n flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n                                                                                                  \n dense (Dense)                  (None, 1024)         38536192    ['flatten[0][0]']                \n                                                                                                  \n dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 1)            1025        ['dropout[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 47,512,481\nTrainable params: 38,537,217\nNon-trainable params: 8,975,264\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    optimizer=RMSprop(learning_rate=0.0001), # Smaller learning rate as we expect high accuracy from start\n    loss = \"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:44.796788Z","iopub.execute_input":"2023-08-05T20:27:44.797148Z","iopub.status.idle":"2023-08-05T20:27:44.851488Z","shell.execute_reply.started":"2023-08-05T20:27:44.797114Z","shell.execute_reply":"2023-08-05T20:27:44.850709Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the dataset","metadata":{}},{"cell_type":"code","source":"# Download the dataset\n!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:44.852551Z","iopub.execute_input":"2023-08-05T20:27:44.852920Z","iopub.status.idle":"2023-08-05T20:27:46.692629Z","shell.execute_reply.started":"2023-08-05T20:27:44.852885Z","shell.execute_reply":"2023-08-05T20:27:46.691402Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"--2023-08-05 20:27:46--  https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 142.250.107.128, 74.125.20.128, 108.177.98.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.250.107.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 68606236 (65M) [application/zip]\nSaving to: ‘cats_and_dogs_filtered.zip’\n\ncats_and_dogs_filte 100%[===================>]  65.43M   159MB/s    in 0.4s    \n\n2023-08-05 20:27:46 (159 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Extract the archive\nzip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\nzip_ref.extractall(\"tmp/\")\nzip_ref.close()\n\n# Define our example directories and files\nbase_dir = 'tmp/cats_and_dogs_filtered'\n\ntrain_dir = os.path.join( base_dir, 'train')\nvalidation_dir = os.path.join( base_dir, 'validation')\n\n# Directory with training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\n\n# Directory with training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\n\n# Directory with validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\n\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary',\n                                                    target_size = (150, 150))\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator =  test_datagen.flow_from_directory( validation_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary',\n                                                          target_size = (150, 150))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:46.695098Z","iopub.execute_input":"2023-08-05T20:27:46.695509Z","iopub.status.idle":"2023-08-05T20:27:47.622054Z","shell.execute_reply.started":"2023-08-05T20:27:46.695466Z","shell.execute_reply":"2023-08-05T20:27:47.621110Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model.\nhistory = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 20,\n            validation_steps = 50,\n            verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:27:47.623308Z","iopub.execute_input":"2023-08-05T20:27:47.623650Z","iopub.status.idle":"2023-08-05T20:33:51.088091Z","shell.execute_reply.started":"2023-08-05T20:27:47.623615Z","shell.execute_reply":"2023-08-05T20:33:51.087018Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/20\n100/100 - 25s - loss: 0.3114 - accuracy: 0.8735 - val_loss: 0.1780 - val_accuracy: 0.9310 - 25s/epoch - 249ms/step\nEpoch 2/20\n100/100 - 14s - loss: 0.2141 - accuracy: 0.9130 - val_loss: 0.1225 - val_accuracy: 0.9550 - 14s/epoch - 144ms/step\nEpoch 3/20\n100/100 - 14s - loss: 0.1911 - accuracy: 0.9230 - val_loss: 0.0939 - val_accuracy: 0.9620 - 14s/epoch - 145ms/step\nEpoch 4/20\n100/100 - 14s - loss: 0.1829 - accuracy: 0.9275 - val_loss: 0.0961 - val_accuracy: 0.9660 - 14s/epoch - 138ms/step\nEpoch 5/20\n100/100 - 14s - loss: 0.1424 - accuracy: 0.9390 - val_loss: 0.1510 - val_accuracy: 0.9430 - 14s/epoch - 137ms/step\nEpoch 6/20\n100/100 - 14s - loss: 0.1608 - accuracy: 0.9450 - val_loss: 0.1001 - val_accuracy: 0.9580 - 14s/epoch - 137ms/step\nEpoch 7/20\n100/100 - 15s - loss: 0.1405 - accuracy: 0.9425 - val_loss: 0.0823 - val_accuracy: 0.9680 - 15s/epoch - 147ms/step\nEpoch 8/20\n100/100 - 14s - loss: 0.1409 - accuracy: 0.9480 - val_loss: 0.0902 - val_accuracy: 0.9670 - 14s/epoch - 137ms/step\nEpoch 9/20\n100/100 - 15s - loss: 0.1603 - accuracy: 0.9375 - val_loss: 0.0919 - val_accuracy: 0.9700 - 15s/epoch - 147ms/step\nEpoch 10/20\n100/100 - 15s - loss: 0.1263 - accuracy: 0.9485 - val_loss: 0.1278 - val_accuracy: 0.9510 - 15s/epoch - 148ms/step\nEpoch 11/20\n100/100 - 14s - loss: 0.1322 - accuracy: 0.9435 - val_loss: 0.1777 - val_accuracy: 0.9450 - 14s/epoch - 137ms/step\nEpoch 12/20\n100/100 - 14s - loss: 0.1290 - accuracy: 0.9455 - val_loss: 0.1157 - val_accuracy: 0.9630 - 14s/epoch - 144ms/step\nEpoch 13/20\n100/100 - 14s - loss: 0.1400 - accuracy: 0.9530 - val_loss: 0.0952 - val_accuracy: 0.9630 - 14s/epoch - 137ms/step\nEpoch 14/20\n100/100 - 15s - loss: 0.1216 - accuracy: 0.9505 - val_loss: 0.0795 - val_accuracy: 0.9710 - 15s/epoch - 146ms/step\nEpoch 15/20\n100/100 - 14s - loss: 0.1225 - accuracy: 0.9535 - val_loss: 0.0904 - val_accuracy: 0.9700 - 14s/epoch - 139ms/step\nEpoch 16/20\n100/100 - 14s - loss: 0.1076 - accuracy: 0.9570 - val_loss: 0.0904 - val_accuracy: 0.9680 - 14s/epoch - 144ms/step\nEpoch 17/20\n100/100 - 14s - loss: 0.1220 - accuracy: 0.9530 - val_loss: 0.0958 - val_accuracy: 0.9720 - 14s/epoch - 137ms/step\nEpoch 18/20\n100/100 - 14s - loss: 0.1151 - accuracy: 0.9585 - val_loss: 0.0976 - val_accuracy: 0.9680 - 14s/epoch - 137ms/step\nEpoch 19/20\n100/100 - 14s - loss: 0.1288 - accuracy: 0.9510 - val_loss: 0.1088 - val_accuracy: 0.9650 - 14s/epoch - 144ms/step\nEpoch 20/20\n100/100 - 14s - loss: 0.1240 - accuracy: 0.9560 - val_loss: 0.0896 - val_accuracy: 0.9650 - 14s/epoch - 137ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluating the results","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T20:35:08.504968Z","iopub.execute_input":"2023-08-05T20:35:08.505361Z","iopub.status.idle":"2023-08-05T20:35:08.864354Z","shell.execute_reply.started":"2023-08-05T20:35:08.505330Z","shell.execute_reply":"2023-08-05T20:35:08.863297Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}