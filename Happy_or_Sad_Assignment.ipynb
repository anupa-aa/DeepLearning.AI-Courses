{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfEL0ZaBYyqAh6z0OCEMRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupa-aa/DeepLearning.AI-Courses/blob/master/Happy_or_Sad_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9KZsYF7S-1PT"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "base_dir = \"./data/\"\n",
        "happy_dir = os.path.join(base_dir, \"happy/\")\n",
        "sad_dir = os.path.join(base_dir, \"sad/\")\n",
        "\n",
        "print(\"Sample happy image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample sad image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "UOSZuDBo_1wJ",
        "outputId": "598d4135-568c-4010-ee00-036904819034"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample happy image:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-459a3728d2dd>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample happy image:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/happy/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Load the first example of a happy face\n",
        "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
        "\n",
        "# Convert the image into its numpy array representation\n",
        "sample_array = img_to_array(sample_image)\n",
        "\n",
        "print(f\"Each image has shape: {sample_array.shape}\")\n",
        "\n",
        "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5dBSFDlb_4RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "L1PBOjj-HBp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# GRADED FUNCTION: image_generator\n",
        "def image_generator():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class.\n",
        "    # Remember to set the rescale argument.\n",
        "    train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "    # Specify the method to load images from a directory and pass in the appropriate arguments:\n",
        "    # - directory: should be a relative path to the directory containing the data\n",
        "    # - targe_size: set this equal to the resolution of each image (excluding the color dimension)\n",
        "    # - batch_size: number of images the generator yields when asked for a next batch. Set this to 10.\n",
        "    # - class_mode: How the labels are represented. Should be one of \"binary\", \"categorical\" or \"sparse\".\n",
        "    #               Pick the one that better suits here given that the labels are going to be 1D binary labels.\n",
        "    train_generator = train_datagen.flow_from_directory(directory=\"./data\",\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode=\"binary\")\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return train_generator\n",
        ""
      ],
      "metadata": {
        "id": "ZgLpJ4R8HD7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Save your generator in a variable\n",
        "gen = image_generator()\n",
        "\n"
      ],
      "metadata": {
        "id": "EIEWJ1j-HGUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "from tensorflow.keras import optimizers, losses\n",
        "\n",
        "# GRADED FUNCTION: train_happy_sad_model\n",
        "def train_happy_sad_model(train_generator):\n",
        "\n",
        "    # Instantiate the callback\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(150,150,3)),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    # Select a loss function compatible with the last layer of your network\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    # Your model should achieve the desired accuracy in less than 15 epochs.\n",
        "    # You can hardcode up to 20 epochs in the function below but the callback should trigger before 15.\n",
        "    history = model.fit(x=gen,\n",
        "                        epochs=20,\n",
        "                        callbacks=[myCallback()]\n",
        "                       )\n",
        "\n",
        "    ### END CODE HERE\n",
        "    return history"
      ],
      "metadata": {
        "id": "vHOnH9NJHIEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "hist = train_happy_sad_model(gen)"
      ],
      "metadata": {
        "id": "0ZzUg0M7HKW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "print(f\"Your model reached the desired accuracy after {len(hist.epoch)} epochs\")"
      ],
      "metadata": {
        "id": "IcWOnW77HMc2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}