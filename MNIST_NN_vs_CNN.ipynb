{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVJtwdui8DpqilOJdQ6Kvi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupa-aa/DeepLearning.AI-Courses/blob/master/MNIST_NN_vs_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 2: Implementing Callbacks in TensorFlow using the MNIST Dataset\n",
        "\n",
        "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy and stops once this threshold is achieved. In the lecture you saw how this was done for the loss but here you will be using accuracy instead.\n",
        "\n",
        "Some notes:\n",
        "1. Your network should succeed in less than 9 epochs.\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\" and stop training.\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class. This is important for the function signatures (the parameters and names) of the callbacks."
      ],
      "metadata": {
        "id": "eLNtjESmemph"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uoAim4mDeheY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os # We need this to load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and inspecting the data"
      ],
      "metadata": {
        "id": "P7JVuj-i-0r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the current working directory and appends the data location\n",
        "# data/mnist.npz to create the full path\n",
        "current_dir = os.getcwd()\n",
        "data_path = os.path.join(current_dir, \"mnist.npz\")\n",
        "\n",
        "# Get the training set and discard the test set\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Normalize the colour values from 0 to 1 instead of 0 to 255\n",
        "x_train = x_train/255.0\n"
      ],
      "metadata": {
        "id": "dObkrRh1-DKy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0GOZKiV_lAA",
        "outputId": "743aa0c9-56a1-4a43-c943-defdbc2b199e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a callback"
      ],
      "metadata": {
        "id": "ZnmM9JfIA14p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get(\"accuracy\") is not None and logs.get(\"accuracy\") > 0.99:\n",
        "      print(\"Reached 99% accuracy so stopping training\")\n",
        "      self.model.stop_training = True\n",
        ""
      ],
      "metadata": {
        "id": "i8zqIjj1Axnu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating our DNN model"
      ],
      "metadata": {
        "id": "pCerhSCeZku_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KK5Xqora-BX",
        "outputId": "be253711-a47c-470f-def1-5622b4b6523f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mnist(x_train, y_train):\n",
        "\n",
        "  # Instantiate call back class\n",
        "  mycallback = myCallback()\n",
        "\n",
        "  # Design our model\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  # Compile our model\n",
        "  model.compile(optimizer=\"adam\",\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  # Fit model for ten epochs adding the callbacks and save history\n",
        "  history = model.fit(x_train, y_train, epochs=10, callbacks = [mycallback])\n",
        "\n",
        "  return history\n",
        "\n"
      ],
      "metadata": {
        "id": "MgvWmW2iZhVT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = train_mnist(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Fy2xQ_apPb",
        "outputId": "2dad6218-08f7-4a04-87a0-d2d06c45296c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2633 - accuracy: 0.9248\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1162 - accuracy: 0.9660\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0796 - accuracy: 0.9759\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0595 - accuracy: 0.9816\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0464 - accuracy: 0.9857\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0366 - accuracy: 0.9887\n",
            "Epoch 7/10\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9912Reached 99% accuracy so stopping training\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0286 - accuracy: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an alternative CNN model"
      ],
      "metadata": {
        "id": "HndZzPojbRZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mnist_cnn(x_train, y_train):\n",
        "\n",
        "  # initialise our callback class\n",
        "  my_callback = myCallback()\n",
        "\n",
        "  # *AS WE ARE USING CONV LAYERS, WE NEED TO CHANGE THE SHAPE OF X_TRAIN\n",
        "  # TO MATCH THE INPUT SIZE OF THE CONV LAYERS\n",
        "  x_train = x_train.reshape(-1,28,28,1)\n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "\n",
        "  # Design our model\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
        "      keras.layers.MaxPooling2D(2,2),\n",
        "      keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "      keras.layers.MaxPooling2D(2,2),\n",
        "      keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(32, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  # Compile our model\n",
        "  model.compile(\n",
        "      optimizer=\"adam\",\n",
        "      loss=\"categorical_crossentropy\",\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Fit our model to the data for 10 epochs with our callbacks\n",
        "  history = model.fit(x_train, y_train, epochs=10, callbacks=[my_callback])\n",
        "\n",
        "  return history"
      ],
      "metadata": {
        "id": "wizX01znatkd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_cnn = train_mnist_cnn(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3zDFmgIdU8Z",
        "outputId": "a23b9581-a2bf-4992-eb2a-9d6a524eb8af"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 39s 20ms/step - loss: 0.1969 - accuracy: 0.9415\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0621 - accuracy: 0.9810\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0461 - accuracy: 0.9856\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0360 - accuracy: 0.9886\n",
            "Epoch 5/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9902Reached 99% accuracy so stopping training\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0310 - accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JMdrdEtTdZ8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}